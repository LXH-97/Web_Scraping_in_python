键入Python网络数据采集书中示例      2018/1/29

日常也可以提交到github

将书中示例自行输入，有助于更好理解书中内容

一直存在ctrl+k提交代码到github没有更新情况

2018/3/27
忙着搞flaskweb,有日子没来弄爬虫了。
上一个问题的解决办法是Ctrl+Shift+K（pycharm的"git push"快捷键）

2018/3/28
Chapter1和2，因为原书第一章属于配置所以跳一章，从第四章恢复原书顺序

2018/4/19
到今天看完了第二遍本书，也才是第一次敲完全部(除了小示例)的代码
温故知新，作者爬虫可以说是很有把握感

启发：
爬虫从几个方面和顺序进行：
1）选择为网页下载和分析库（什么时候xpath，bs4，或者requests、scrapy
2）API合法批量下载
3）数据库的使用以存储爬取数据
4）更多的文档格式和语言系（csv、pdf，utf-8。。。）
5）数据清理（网页的标记代码清洗）
6)自然语言处理
7）表单
8）JavaScript（动态采集）
9）Ocr（Optical Character Recognise)
10)爬虫与反爬虫
11）以爬虫测试网站
12）远程采集（服务器代理IP）